



import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
import seaborn as sns

# Assuming merged_df is your DataFrame

import time
import open3d as o3d
import numpy as np
import pyvista as pv
import time
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Qt5Agg')

import open3d as o3d
import numpy as np
import pyvista as pv
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
print(np.__version__)
matplotlib.use('Qt5Agg')
import os
import pandas as pd

# Define the folder path containing the mesh files
folder_path = "C:/Users\matan.yuval\Desktop\FinalExperiment2\FinalPointClouds"

# Initialize an empty DataFrame for merged results
merged_df = pd.DataFrame()

# Iterate over each file in the folder
for step_counter, file_name in enumerate(os.listdir(folder_path)):
    if file_name.endswith(".ply"):  # Adjust this extension check as needed
        file_path = os.path.join(folder_path, file_name)

        # Load the mesh (assuming a function to load based on your setup)
        pcd = o3d.io.read_point_cloud(file_path)  # Replace `load_mesh_function` with actual function
        obb = pcd.get_axis_aligned_bounding_box()#.get_oriented_bounding_box()#pcd.get_oriented_bounding_box()
        obb_corners = np.asarray(obb.get_box_points())  # Get the 8 corners of the OBB
        bottom_corner = obb_corners.min(axis=0)  # The lowest corner in all axes
        translation_vector = -bottom_corner  # Translation to move the bottom corner to (0, 0, 0)
        pcd.translate(translation_vector)
        points = np.asarray(pcd.points)
        pcd_colors = np.asarray(pcd.colors)
        print('run Poisson surface reconstruction')
        with o3d.utility.VerbosityContextManager(
                o3d.utility.VerbosityLevel.Debug) as cm:
            mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(
                pcd, depth=9)
        min_bound = mesh.get_min_bound()  # [x_min, y_min, z_min]
        max_bound = mesh.get_max_bound()  # [x_max, y_max, z_max]
        # Initialize step sizes
        y_min = np.min(points[:, 1]) #+ 0.2
        y_max = np.max(points[:, 1]) #- 0.2
        # Run the directed geodesic walk on the mesh
        step_counter_df = directed_geodesic_walk(mesh, y_min, y_max)
        # Convert the result to a DataFrame if needed
        step_counter_df = pd.DataFrame(step_counter_df)
        # Add the 'site' column based on the step counter or file name
        base_name = os.path.basename(file_name)
        site_name = base_name.split('_')[0]
        step_counter_df['site'] = site_name
        # Merge the result into the main DataFrame
        merged_df = pd.concat([merged_df, step_counter_df], axis=0, ignore_index=True)
merged_df['walk_ratio'] = merged_df['distance']/ merged_df['geodesic_length']
merged_df['log_walk_ratio'] = np.log(merged_df['walk_ratio'])
merged_df['log_step size'] = np.log(merged_df['step size'])
merged_df['log_num_steps'] = np.log(merged_df['num_steps'])
merged_df['1/step size'] = 1 / merged_df['step size']
merged_df['log_1/step size'] = np.log(merged_df['1/step size'])
merged_df = merged_df[merged_df['num_steps'] == 0]


unique_sites = merged_df['site'].unique()
colors = sns.color_palette("Set1", len(unique_sites))  # Unique color for each site

plt.figure(figsize=(12, 8))

for site_idx, site in enumerate(unique_sites):
    site_df = merged_df[merged_df['site'] == site]

    # x and y values for fitting
    x = site_df['log_1/step size'].values.reshape(-1, 1)
    y = site_df['log_walk_ratio'].values

    # Linear regression
    regressor = LinearRegression()
    regressor.fit(x, y)
    slope = regressor.coef_[0]
    intercept = regressor.intercept_

    # Predict values for the fitted line
    x_pred = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)
    y_pred = regressor.predict(x_pred)

    # Plot the fitted line and scatter points for each site
    plt.plot(x_pred, y_pred, color=colors[site_idx], linewidth=12, alpha=0.8,
             label=f'{site} (slope = {slope:.3f}), intercept = {intercept:.3f} ')
    plt.scatter(x, y, color=colors[site_idx], alpha=0.05, s=20)  # Scatter plot for data points

# Configure plot
plt.xlabel('log(1 / step size)', fontsize=18)
plt.ylabel('log(walk ratio)', fontsize=18)
plt.title('Linear Fit of log(walk ratio) vs. log(1 / step size) for Each Site', fontsize=18)
plt.legend(fontsize=18, title="Sites and Slopes", title_fontsize=18)
plt.show()

def directed_geodesic_walk(mesh, y_min, y_max):
    step_sizes = [0.01, 0.02, 0.03, 0.05, 0.07, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 0.99, 1.1, 1.2, 1.4, 1.5, 1.7, 2, 2.5, 3, 5]
    step_counter_df = []

    min_bound = np.min(np.asarray(mesh.vertices), axis=0)
    max_bound = np.max(np.asarray(mesh.vertices), axis=0)

    step_size = 0.01
    slice_size = 0.05
    for y in np.arange(y_min, y_max, step_size)[::10]:
        y = np.round(y, 3)
        print(y)
        crop_min_bound = [min_bound[0], y, min_bound[2]]
        crop_max_bound = [max_bound[0], y + slice_size, max_bound[2]]

        cropped_mesh = mesh.crop(o3d.geometry.AxisAlignedBoundingBox(crop_min_bound, crop_max_bound))
        cropped_mesh.translate(np.array([0, 0, 1]))
        vertices = np.asarray(cropped_mesh.vertices)
        triangles = np.asarray(cropped_mesh.triangles)
        formatted_triangles = np.hstack([np.full((triangles.shape[0], 1), 3), triangles])
        pv_mesh = pv.PolyData(vertices, formatted_triangles).extract_largest()

        # Compute forward geodesic path
        min_x_index = np.argmin(pv_mesh.points[:, 0])
        max_x_index = np.argmax(pv_mesh.points[:, 0])
        geodesic_path = pv_mesh.geodesic(min_x_index, max_x_index)
        geodesic_points = geodesic_path.points
        length = np.sum(np.linalg.norm(np.diff(geodesic_points, axis=0), axis=1))

        # Reverse the geodesic path points
        rev_geodesic_points = geodesic_points[::-1]
        rev_length = np.sum(np.linalg.norm(np.diff(rev_geodesic_points, axis=0), axis=1))

        # Convert geodesic paths to Open3D PointCloud
        pcd_for_walk = o3d.geometry.PointCloud()
        pcd_for_walk.points = o3d.utility.Vector3dVector(geodesic_points)
        pcd_for_walk_dense = densify_point_cloud(densify_point_cloud(densify_point_cloud(pcd_for_walk)))

        rev_pcd_for_walk_dense = o3d.geometry.PointCloud()
        rev_pcd_for_walk_dense.points = o3d.utility.Vector3dVector(rev_geodesic_points)
        rev_pcd_for_walk_dense = densify_point_cloud(densify_point_cloud(densify_point_cloud(rev_pcd_for_walk_dense)))

        pcd_tree = o3d.geometry.KDTreeFlann(pcd_for_walk_dense)
        rev_pcd_tree = o3d.geometry.KDTreeFlann(rev_pcd_for_walk_dense)

        for radius in step_sizes:
            counter, current_index, distance_on_path = 0, 0, 0
            current_point = pcd_for_walk_dense.points[current_index]
            target_point = pcd_for_walk_dense.points[-1]

            while np.linalg.norm(current_point - target_point) > radius:
                radius_small = radius - 0.005
                _, idx1, _ = pcd_tree.search_radius_vector_3d(current_point, radius_small)
                _, idx2, _ = pcd_tree.search_radius_vector_3d(current_point, radius)
                neighbor_steps = np.array(list(set(idx2) - set(idx1)), dtype=int)

                valid_neighbor_indices = [idx for idx in neighbor_steps if idx > current_index]

                if len(valid_neighbor_indices) == 0:
                    counter = 0
                    break
                if np.linalg.norm(current_point - target_point) < radius:
                    distance_on_path += np.linalg.norm(current_point - target_point)
                    counter += 1
                    break
                minimal_neighbor = min(valid_neighbor_indices, key=lambda idx: pcd_for_walk_dense.points[idx][0])
                current_index = minimal_neighbor
                distance_on_path += np.linalg.norm(current_point - pcd_for_walk_dense.points[current_index])
                current_point = pcd_for_walk_dense.points[current_index]
                counter += 1

            # Reverse walk
            rev_counter, rev_current_index, rev_distance_on_path = 0, 0, 0
            rev_current_point = rev_pcd_for_walk_dense.points[rev_current_index]
            rev_target_point = rev_pcd_for_walk_dense.points[-1]

            while np.linalg.norm(rev_current_point - rev_target_point) > radius:
                _, idx1, _ = rev_pcd_tree.search_radius_vector_3d(rev_current_point, radius_small)
                _, idx2, _ = rev_pcd_tree.search_radius_vector_3d(rev_current_point, radius)
                rev_neighbor_steps = np.array(list(set(idx2) - set(idx1)), dtype=int)

                rev_valid_neighbor_indices = [idx for idx in rev_neighbor_steps if idx > rev_current_index]

                if len(rev_valid_neighbor_indices) == 0:
                    rev_counter = 0
                    break
                if np.linalg.norm(rev_current_point - rev_target_point) < radius:
                    rev_distance_on_path += np.linalg.norm(rev_current_point - rev_target_point)
                    rev_counter += 1
                    break
                rev_minimal_neighbor = max(rev_valid_neighbor_indices,
                                           key=lambda idx: rev_pcd_for_walk_dense.points[idx][0])
                rev_current_index = rev_minimal_neighbor
                rev_distance_on_path += np.linalg.norm(
                    rev_current_point - rev_pcd_for_walk_dense.points[rev_current_index])
                rev_current_point = rev_pcd_for_walk_dense.points[rev_current_index]
                rev_counter += 1
            print(radius, counter, rev_counter)
            # Collect data
            step_counter_df.append({
                'y_coord': y,
                'num_steps': (counter + rev_counter) / 2 if counter != 0 and rev_counter != 0 else 0,
                'step size': radius,
                'distance': (distance_on_path + rev_distance_on_path) / 2,
                'geodesic_length': (length + rev_length) / 2,
                'euclidean_distance': np.linalg.norm(pv_mesh.points[min_x_index] - pv_mesh.points[max_x_index]),
            })

    return step_counter_df




# Define the folder path containing the mesh files
folder_path = "C:/Users\matan.yuval\Desktop\FinalExperiment2\FinalPointClouds"

# Initialize an empty DataFrame for merged results
merged_df = pd.DataFrame()

# Iterate over each file in the folder
for step_counter, file_name in enumerate(os.listdir(folder_path)):
    if file_name.endswith(".ply"):  # Adjust this extension check as needed
        file_path = os.path.join(folder_path, file_name)

        # Load the mesh (assuming a function to load based on your setup)
        pcd = o3d.io.read_point_cloud(file_path)  # Replace `load_mesh_function` with actual function
        obb = pcd.get_minimal_oriented_bounding_box()
        print(obb.extent , file_name)
        obb = pcd.get_axis_aligned_bounding_box()#.get_oriented_bounding_box()#pcd.get_oriented_bounding_box()

        obb_corners = np.asarray(obb.get_box_points())  # Get the 8 corners of the OBB
        bottom_corner = obb_corners.min(axis=0)  # The lowest corner in all axes
        translation_vector = -bottom_corner  # Translation to move the bottom corner to (0, 0, 0)
        pcd.translate(translation_vector)
        points = np.asarray(pcd.points)
        pcd_colors = np.asarray(pcd.colors)

        # Define the cube size
        cube_size = obb.get_max_extent()

        # Step 2: Create cube corners with one corner at the origin (0,0,0)
        new_corners = np.array([
            [0, 0, 0],  # Bottom-left-back
            [cube_size, 0, 0],  # Bottom-right-back
            [cube_size, cube_size, 0],  # Bottom-right-front
            [0, cube_size, 0],  # Bottom-left-front
            [0, 0, cube_size],  # Top-left-back
            [cube_size, 0, cube_size],  # Top-right-back
            [cube_size, cube_size, cube_size],  # Top-right-front
            [0, cube_size, cube_size]  # Top-left-front
        ])

        # Step 3: Create a new AABB (cube) from the new corners
        cube = o3d.geometry.OrientedBoundingBox.create_from_points(o3d.utility.Vector3dVector(new_corners))
        cube = o3d.geometry.AxisAlignedBoundingBox.create_from_points(o3d.utility.Vector3dVector(new_corners))
        cube.color = (1, 0, 0)  # Color the cube for visualization purposes
        FD_df = pd.DataFrame(columns=['side_length', '_num_cubes_p_depth'])
        #minimal_cube_size = 0.2
        cube_counting_df = divide_cube2(cube, pcd, 0, FD_df, 0.02)
        # Convert the result to a DataFrame if needed
        cube_counting_df = pd.DataFrame(cube_counting_df)
        # Add the 'site' column based on the step counter or file name
        base_name = os.path.basename(file_name)
        site_name = base_name.split('_')[0]
        cube_counting_df['site'] = site_name
        # Merge the result into the main DataFrame
        merged_df = pd.concat([merged_df, cube_counting_df], axis=0, ignore_index=True)
merged_df.to_csv("CubeCountingFinalExperiment.txt", sep="\t", index=False)
merged_df['1/log_side_length'] = np.log(1/merged_df['side_length'])
merged_df['log_num_cubes'] = np.log(merged_df['_num_cubes_p_depth'])

unique_sites = merged_df['site'].unique()
colors = sns.color_palette("Set1", len(unique_sites))  # Unique color for each site

def add_jitter(values, jitter_amount=0.02):
    return values + np.random.uniform(-jitter_amount, jitter_amount, size=len(values))


# Loop through each site to plot the data
for site_idx, site in enumerate(merged_df['site'].unique()):
    site_data = merged_df[merged_df['site'] == site]
    x = site_data['1/log_side_length']
    y = site_data['log_num_cubes']

    # Add jitter to x and y values for scatter plot
    x_jittered = add_jitter(x)
    y_jittered = add_jitter(y)

    # Perform linear fit
    slope, intercept = np.polyfit(x, y, 1)
    x_pred = np.linspace(x.min(), x.max(), 100)
    y_pred = slope * x_pred + intercept
    print(site,slope)
    # Plot the fitted line and jittered scatter points for each site
    plt.plot(x_pred, y_pred, color=colors[site_idx], linewidth=2, alpha=0.7,
             label=f'{site}, FD(slope)={slope:.3f}')
    plt.scatter(x_jittered, y_jittered, color=colors[site_idx], alpha=0.6, s=30)  # Jittered scatter plot

# Configure the plot
plt.xlabel('log(1 / side length)', fontsize=18)
plt.ylabel('log(Number of Cubes per Depth)', fontsize=18)
plt.title('Linear Fit of log(Number of Cubes) vs. log(1 / Side Length) for Each Site', fontsize=24)
plt.legend(fontsize=18, title="Sites and Slopes", title_fontsize=18)
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)
plt.grid(True, linestyle='--', alpha=0.6)  # Optional: Add a grid for better visualization
plt.show()


# Function to create a sub-cube with a specified color
def create_subcube(min_corner, max_corner, color):
    bbox = o3d.geometry.AxisAlignedBoundingBox(min_corner, max_corner)
    bbox.color = color  # Set the color
    return bbox


# Recursive function to divide the cube, track data per depth, and save cube centers and children info
def divide_cube2(cube, pcd, depth, FD_df, minimal_cube_size):
    # Get the center and corners of the cube
    point_indices = cube.get_point_indices_within_bounding_box(pcd.points)

    # Check if the current bounding box is empty
    if not point_indices:
        return FD_df  # No points are within this bounding box, exit

    pcd_sub = pcd.select_by_index(point_indices)
    # Get cube center and side length
    center = cube.get_center()
    corners = np.asarray(cube.get_box_points())
    side_length = np.linalg.norm(corners[0] - corners[1])

    # Update FD_df
    if depth in FD_df.index:
        FD_df.loc[depth, '_num_cubes_p_depth'] += 1
    else:
        # Add a new entry for the current depth
        FD_df.loc[depth] = [side_length, 1]

    # Check if the cube should be subdivided
    if side_length > minimal_cube_size:
        # Generate the 8 subcubes
        for i in [0, 1]:
            for j in [0, 1]:
                for k in [0, 1]:
                    min_corner = np.array([
                        corners[0][0] if i == 0 else center[0],
                        corners[0][1] if j == 0 else center[1],
                        corners[0][2] if k == 0 else center[2]
                    ])
                    max_corner = np.array([
                        center[0] if i == 0 else corners[4][0],
                        center[1] if j == 0 else corners[4][1],
                        center[2] if k == 0 else corners[4][2]
                    ])
                    subcube = create_subcube(min_corner, max_corner, color=[1, 0, 0])
                    # Call the function recursively on the new sub-cube
                    FD_df = divide_cube2(subcube, pcd_sub, depth + 1, FD_df, minimal_cube_size)

    return FD_df  # Return the updated FD_df

